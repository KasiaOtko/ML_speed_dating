source('C:/Users/tuhe/Dropbox/02450_public/Exercises/02450Toolbox_R/Scripts/ex3_2_1.R', echo=TRUE)
help std
help(var)
source('C:/Users/tuhe/Dropbox/02450_public/Exercises/02450Toolbox_R/Scripts/ex3_2_1.R', echo=TRUE)
Xdatframe_test <- data.frame(X_test)
colnames(Xdatframe_test) <- attributeNames
# Compute classification error
for(n in 1:length(prune)){ # For each pruning level
mytree_pruned <- prune(mytree,prune[n])
predicted_classes_train<- classNames[predict(mytree_pruned, newdat=Xdatframe_train, type="vector")]
predicted_classes_test<- classNames[predict(mytree_pruned, newdat=Xdatframe_test, type="vector")]
Error_train[n] = sum(classNames[y_train+1]!= predicted_classes_train)
Error_test[n] = sum(classNames[y_test+1]!= predicted_classes_test)
}
# Plot classification error
plot(c(min(prune), max(prune)), c(min(Error_train/CV$TrainSize, Error_test/CV$TestSize), max(Error_train/CV$TrainSize, Error_test/CV$TestSize)), main='Wine decision tree: Holdout crossvalidation', xlab = 'Pruning level', ylab='Classification error', type="n")
points(prune, Error_train/CV$TrainSize, col="blue")
points(prune, Error_test/CV$TestSize, col="red");
legend('topleft', legend=c('Training error', 'Test error'), fill=c("blue", "red"));
rm(list=ls())
source("setup.R")
library(rpart)
library(cvTools)
# Load data
library(R.matlab)
dat <- readMat(file.path('Data', 'wine2.mat'))
X <- dat$X
setwd("C:/Users/tuhe/Dropbox/02450_public/Exercises/02450Toolbox_R/Scripts")
# exercise 6.1.1
rm(list=ls())
source("setup.R")
library(cvTools)
library(rpart)
# Load data
library(R.matlab)
source('C:/Users/tuhe/Dropbox/02450_public/Exercises/02450Toolbox_R/Scripts/ex9_2_2.R', echo=TRUE)
library(FNN) # if the package FNN is not already installed, install it using install.packages("FNN")
?knn
####################
# exercise 2.1.2
####################
# Run ex2.1.1:
source('Scripts/ex2_1_1.R')
setwd("C:/Users/katin/Desktop/Folder/STUDIA/DTU/Semestr I/Intro to ML/02450Toolbox_R")
####################
# exercise 2.1.2
####################
# Run ex2.1.1:
source('Scripts/ex2_1_1.R')
####################
# exercise 2.1.2
####################
# Run ex2.1.1:
source('Scripts/ex2_1_1.R')
# choose which sensors to plot
i = 1
j = 2
## Make simple plot
plot(X[ , i], X[ , j])
## Make more fancy plot
# First assign titles and labels to the plot, and determine its size by giving the minimum and maximum values of the sensors.
# Do not plot anything (the option type="n")
plot(c(min(X[ , i]), max(X[ , i])), c(min(X[ , j]), max(X[ , j])),
xlab=attributeNames[i], ylab=attributeNames[j],
main="NanoNose data", type="n")
## Make more fancy plot
# First assign titles and labels to the plot, and determine its size by giving the minimum and maximum values of the sensors.
# Do not plot anything (the option type="n")
plot(c(min(X[ , i]), max(X[ , i])), c(min(X[ , j]), max(X[ , j])),
xlab=attributeNames[i], ylab=attributeNames[j],
main="NanoNose data")
# plot points for each sensor in separate colors
library(colorRamps); cols <- colorRamps::matlab.like2(C); library(scales)
####################
# exercise 2.1.2
####################
# Run ex2.1.1:
install.packages('colorRamps')
# plot points for each sensor in separate colors
library(colorRamps); cols <- colorRamps::matlab.like2(C); library(scales)
for(c in 0:C-1){
points(X[y==c, i], X[y==c, j], pch=19,cex=2, col=alpha(cols[c+1],.33))
}
cols
C
X
X[1, 1]
X[1, ]
y
# add legend
legend("topright", legend=classNames, fill = cols)
####################
# exercise 2.1.3
####################
source('Scripts/ex2_1_1.R')
Y<- t(apply(X,1,'-',colMeans(X))) # subtract the column means form columns of X
Y
colMeans(X)
X
# PCA by computing SVD of Y:
s <- svd(Y)
s
diagS <- s$d
rho <- diagS^2/sum(diagS^2)
#sum(pcvariance[1:3])
threshold = 0.9
rho
sum(rho)
#sum(pcvariance[1:3])
threshold = 0.9
xlimits <- c(1, M);
xlimits
plot(rho,
type='o',
main="Variance explained by principal componenets",
xlab="Principal components",
ylab="Variance explained",
xlim=xlimits,
ylim=c(0,1),
col='blue')
lines(cumsum(rho), type='o', col='orange')
lines(xlimits, c(threshold, threshold), lty='dashed')
legend("right", # Define position
legend=c("Individual", "Cumulative", "Threshold"), # Set strings for legend
col=c("orange", "blue", "black"), lty=c(1,1,2), # Match appereance of lines
cex=1.5, bg='lightblue') # Setup how the box looks (cex controls size)
legend("right", # Define position
legend=c("Cumulative", "Individual", "Threshold"), # Set strings for legend
col=c("orange", "blue", "black"), lty=c(1,1,2), # Match appereance of lines
cex=1.5, bg='lightblue') # Setup how the box looks (cex controls size)
legend("right", # Define position
legend=c("Cumulative", "Individual", "Threshold"), # Set strings for legend
col=c("orange", "blue", "black"), lty=c(1,1,2), # Match appereance of lines
cex=1.5, bg='lightblue') # Setup how the box looks (cex controls size)
?apply
apply(X,1,'-',colMeans(X))
Y<- t(apply(X,1,'-',colMeans(X))) # subtract the column means form columns of X
xlimits <- c(1, M);
plot(rho,
type='o',
main="Variance explained by principal componenets",
xlab="Principal components",
ylab="Variance explained",
xlim=xlimits,
ylim=c(0,1),
col='blue')
lines(cumsum(rho), type='o', col='orange')
lines(xlimits, c(threshold, threshold), lty='dashed')
legend("right", # Define position
legend=c("Cumulative", "Individual", "Threshold"), # Set strings for legend
col=c("orange", "blue", "black"), lty=c(1,1,2), # Match appereance of lines
cex=1.5, bg='lightblue') # Setup how the box looks (cex controls size)
Y<- t(apply(X,1,'-',colMeans(X))) # subtract the column means form columns of X
# PCA by computing SVD of Y:
s <- svd(Y)
diagS <- s$d
rho <- diagS^2/sum(diagS^2)
#sum(pcvariance[1:3])
threshold = 0.95
xlimits <- c(1, M);
plot(rho,
type='o',
main="Variance explained by principal componenets",
xlab="Principal components",
ylab="Variance explained",
xlim=xlimits,
ylim=c(0,1),
col='blue')
lines(cumsum(rho), type='o', col='orange')
lines(xlimits, c(threshold, threshold), lty='dashed')
####################
# exercise 2.1.4
####################
source('Scripts/ex2_1_3.R')
Z <- s$u%*%diag(s$d)
i <- 1
s
diag(s$d)
Z <- s$u%*%diag(s$d)
i <- 1
j <- 3
plot(c(min(Z[ , i]), max(Z[ , i])), c(min(Z[ , j]), max(Z[ , j])),
xlab=paste('PC',toString(i)), ylab=paste('PC',toString(j)),
main="NanoNose data: PCA", type="n")
# plot points for each sensor in separate colors
cols <- colorRamps::matlab.like2(C) ;
for(c in 0:C-1){
points(Z[y==c, i], Z[y==c, j], pch=19,cex=2, col=alpha(cols[c+1],.33))
}
# add legend
legend("bottomright", legend=classNames, fill = cols)
source('Scripts/ex2_1_3.R')
Z
Z
source('Scripts/ex2_1_2.R')
install.packages("colorRamps")
####################
# exercise 2.1.4
####################
source('Scripts/ex2_1_3.R')
source('Scripts/ex2_1_2.R')
install.packages("colorRamps")
plot(c(min(Z[ , i]), max(Z[ , i])), c(min(Z[ , j]), max(Z[ , j])),
xlab=paste('PC',toString(i)), ylab=paste('PC',toString(j)),
main="NanoNose data: PCA", type="n")
# plot points for each sensor in separate colors
cols <- colorRamps::matlab.like2(C) ;
for(c in 0:C-1){
points(Z[y==c, i], Z[y==c, j], pch=19,cex=2, col=alpha(cols[c+1],.33))
}
# add legend
legend("bottomright", legend=classNames, fill = cols)
####################
# exercise 2.1.5
####################
source('Scripts/ex2_1_1.R')
Y <- t(apply(X,1,'-',colMeans(X))) # subtract the column means form columns of X
# PCA by computing SVD of Y:
s <- svd(Y)
V <- s$v
library(ggplot2) # install.packages('ggplot2)
# We saw in 2.1.3 that the first 3 components explaiend more than 90
# percent of the variance. Let's look at their coefficients:
pcs <- 1:3
# Make some legend strings:
legendStrings = c()
for (pc in pcs) { legendStrings = c(legendStrings, paste('PC',toString(pc))) }
legendStrings
# Make a bar plot for coefficients:
mids <- barplot(t(V[, pcs]), beside=T,
col=c('blue','orange','green'),
legend=legendStrings,
xlab='Attributes',
ylab='Component coefficients',
border="white")
axis(1, at=mids[2,], labels=attributeNames)
grid(lty='solid')
# Inspecting the plot, we see that the 2nd principal component has large
# (in magnitude) coefficients for attributes A, E and H. We can confirm
# this by looking at it's numerical values directly, too:
print('PC2:')
print(V[,1])
# Projection of water class onto the 2nd principal component.
water <- Y[y==4,]
print('First water observation')
print(water[1,])
# You can determine the projection by (remove comments):
print('...and its projection onto PC2')
print(t(water[1,])%*%V[,2])
print('First water observation')
print(water[1,])
# You can determine the projection by (remove comments):
print('...and its projection onto PC2')
print(t(water[1,])%*%V[,2])
setwd('C:/Users/katin/Desktop/Folder/STUDIA/DTU/Semestr I/Intro to ML/Project I')
SD <- read.csv('Speed Dating Data.csv')
# numdim(SDber of rows and columns
dim(SD)
# number of women
length(unique(SD$iid[which(SD$gender == 0)])) # 274
# number of men
length(unique(SD$iid[which(SD$gender == 1)])) # 277
274 + 277
NAs <- sapply(SD, function(x) sum(is.na(x)))
sort(NAs[which(NAs > 0)])
#filling one missing value in last id row
SD[which(is.na(SD$id)), 1:2] <- 22
# filling 10 missing values in pid columns
SD[which(is.na(SD$pid)), 1:15] # partner's id - 7
SD[which(SD$id == 7 & SD$wave == 5), 1:2] # we have to fill these 10 NAs with 128
SD[which(is.na(SD$pid)), 'pid'] <- 128
#filling one missing value in last id row
SD[which(is.na(SD$id)), 1:2] <- 22
# filling 10 missing values in pid columns
SD[which(is.na(SD$pid)), 1:15] # partner's id - 7
SD[which(SD$id == 7 & SD$wave == 5), 1:2] # we have to fill these 10 NAs with 128
SD[which(is.na(SD$pid)), 'pid'] <- 128
# adding one column with explanation for race column (matching index with race names)
race_idx <- unique(SD$race)
race_idx
# adding one column with explanation for race column (matching index with race names)
race_idx <- unique(SD$race)
race_val <- c('Asian', 'European', 'Other', 'Latino', 'Black', NA)
SD$race_explained <- race_val[match(SD$race, race_idx)]
# adding one column with explanation for field_cd column (matching index with race names)
# DISCUSS WITH ALVILS IMPUTING DATA INTO field_cd as 9 (because field is Operations Research)
field_idx <- c(1:18, NA)
# adding one column with explanation for field_cd column (matching index with race names)
# DISCUSS WITH ALVILS IMPUTING DATA INTO field_cd as 9 (because field is Operations Research)
field_idx <- c(1:18, NA)
field_val <- c('Law', 'Math', 'Social Science, Psychologist', 'Medical Science/Pharmaceuticals/Bio Tech',
'Engineering', 'English/Creative Writing/ Journalism', 'History/Religion/Philosophy',
'Business/Econ/Finance', 'Education, Academia', 'Biological Sciences/Chemistry/Physics',
'Social Work', 'Undergrad/undecided', 'Political Science/International Affairs',
'Film', 'Fine Arts/Arts Administration', 'Languages', 'Architecture', 'Other', 'Other')
SD$field_explained <- field_val[match(SD$field_cd, field_idx)]
duplicated(SD[,1])
subset(SD, !duplicated(SD[,1]))
nrow(SD)
SD %>% nrow()
age_df <- subset(SD, !duplicated(SD[,1])) %>%
filter(!is.na(age)) %>%
group_by(wave, gender) %>%
summarize(Average_age = mean(age))
library(dplyr)
SD %>% nrow()
age_df <- subset(SD, !duplicated(SD[,1])) %>%
filter(!is.na(age)) %>%
group_by(wave, gender) %>%
summarize(Average_age = mean(age))
age_df
age_df$gender <- ifelse(age_df$gender == 0, 'Women', 'Men')
age_df
age_df %>% ggplot(aes(x = age, color = factor(gender))) +
geom_histogram(bins = 37, fill = 'white', position = 'identity', alpha = .7) +
geom_vline(aes(xintercept = mean), col = 'red', linetype = 'dashed')
library(ggplot2)
# Mean age per wave
age_df %>% ggplot(aes(x = wave, y = Average_age, fill = gender)) +
geom_bar(stat = 'identity', position = 'dodge') +
scale_fill_discrete(name = "Gender")
age_df <- subset(SD, !duplicated(SD$iid), select = c(iid, gender, age)) %>%
filter(!is.na(age)) %>%
mutate(mean = mean(age))
age_df
age_df %>% ggplot(aes(x = age, color = factor(gender))) +
geom_histogram(bins = 37, fill = 'white', position = 'identity', alpha = .7) +
geom_vline(aes(xintercept = mean), col = 'red', linetype = 'dashed')
age_df %>% ggplot(aes(x = age)) +
geom_histogram(bins = 37, fill = 'white', position = 'identity', alpha = .7) +
geom_vline(aes(xintercept = mean), col = 'red', linetype = 'dashed')
age_df %>% ggplot(aes(x = age)) +
geom_histogram(bins = 37, fill = 'lightgrey', position = 'identity', alpha = .7) +
geom_vline(aes(xintercept = mean), col = 'red', linetype = 'dashed')
# Field analysis
field_df <- subset(SD, !duplicated(SD$iid)) %>%
filter(!is.na(field_cd)) %>%
group_by(field_explained, gender) %>%
summarize(field_sum = n())
field_df$gender <- ifelse(field_df$gender == 0, 'Women', 'Men')
field_df %>% ggplot(aes(x = field_explained, y = field_sum, fill = gender)) +
geom_bar(stat = 'identity', position = 'dodge') +
coord_flip()
# Income
income_df <- subset(SD, !duplicated(SD$iid)) %>%
filter(!is.na(income))
income_df$gender <- ifelse(income_df$gender == 0, 'Women', 'Men')
income_df %>% ggplot(aes(x = income/1000, fill = gender)) +
geom_histogram(bins = 15)
