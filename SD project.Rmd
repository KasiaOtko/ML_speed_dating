

```{r, message=F, warning=F}
library(rapport)
library(rapportools)
library(devtools)
library(dplyr)
library(ggplot2)
library(reshape2)
library(knitr)
library(tidyr)
setwd('C:/Users/katin/Desktop/Folder/STUDIA/DTU/Semestr I/Intro to ML/Project I')

setwd("/home/nomow/Documents/DTU/Intro_to_machine_learning/ML_speed_dating")

# mode functions
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

SD <- read.csv('Speed Dating Data.csv')

# numdim(SDber of rows and columns
dim(SD)

# number of women
length(unique(SD$iid[which(SD$gender == 0)])) # 274

# number of men
length(unique(SD$iid[which(SD$gender == 1)])) # 277

```


## Missing values
```{r}
NAs <- sapply(SD, function(x) sum(is.na(x)))
sort(NAs[which(NAs > 0)]) 

#filling one missing value in last id row
SD[which(is.na(SD$id)), 1:2] <- 22

# filling 10 missing values in pid columns
SD[which(is.na(SD$pid)), 1:15] # partner's id - 7
SD[which(SD$id == 7 & SD$wave == 5), 1:2] # we have to fill these 10 NAs with 128
SD[which(is.na(SD$pid)), 'pid'] <- 128

# filling missing values in columns <attribute_name>1_1
DF <- SD[, 70:75]
df <- DF[!complete.cases(DF),]

dim(df); sum(rowSums(df, na.rm = T) == 100) # so there are 42 rows where we can impute 0s
df[which(df[,1] + df[,2] + df[,3] == 100),]
df[which(df[,1] + df[,2] + df[,3] == 100), c(4:6)] <- 0
df[which(df[,1] + df[,2] + df[,3] + df[,4] == 100),]
df[which(df[,1] + df[,2] + df[,3] + df[,4] == 100), c(5:6)] <- 0
df[which(df[,1] + df[,2] + df[,3] + df[,4] +df[, 5] == 100),]
df[which(df[,1] + df[,2] + df[,3] + df[,4] +df[, 5] == 100), 6] <- 0
DF[!complete.cases(DF),] <- df
SD[,70:75] <- DF

##
df <- subset(SD, !duplicated(SD$iid))
df[,1]
67/nrow(df)
NAs <- sapply(df, function(x) sum(is.na(x))); NAs
NAs_sum <- sum(NAs); NAs_sum

## data filtering
# assigns Mode value for each iid group where value is NA
cols = c("imprelig", "imprace", "goal", "date", "go_out",  "sports", "tvsports", "exercise", "dining", "museums", "art", "hiking","gaming", "clubbing", "reading", "tv", "theater", "movies", "concerts", "music", "shopping", "yoga", "exphappy") 
for (col in cols) {
    pf_o <- SD %>%group_by(iid) %>%  summarize_at( .vars = col, .funs = Mode)
    idx = which(is.na(SD[, col]) == T)
    pf_o[is.na(pf_o)] = 0
    SD[idx, col] = pf_o[SD[idx,]$iid, 2]
}
# assigns Mean value for each iid group where value is NA
cols = c("attr1_1",  "sinc1_1",  "intel1_1", "fun1_1",   "amb1_1" ,  "shar1_1",  "attr2_1",  "sinc2_1", "intel2_1",  "fun2_1",   "amb2_1" ,  "shar2_1", "attr1_2",  "sinc1_2", "intel1_2", "fun1_2",   "amb1_2",   "shar1_2",  "attr3_2",  "sinc3_2",  "intel3_2", "fun3_2" ,"amb3_2", "attr3_1", "sinc3_1", "fun3_1", "intel3_1" ,"amb3_1", "attr", "sinc", "intel", "fun", "amb", "shar", "like", "prob")
for (col in cols) {
    pf_o <- SD %>%group_by(iid) %>%  summarize_at( .vars = col, .funs = mean)
    idx = which(is.na(SD[, col]) == T)
    pf_o[is.na(pf_o)] = 0
    SD[idx, col] = pf_o[SD[idx,]$iid, 2]
}

## age_o filtering
age_o <- SD %>%group_by(iid) %>%  summarise(mode = Mode(age))
idx = which(is.na(SD$age_o) == T)
SD[idx, "age_o"] = age_o[SD[idx,]$pid, ]$mode

## race_o filtering
race_o <- SD %>%group_by(iid) %>%  summarise(mode = Mode(race))
idx = which(is.na(SD$race_o) == T)
SD[idx, "race_o"] = age_o[SD[idx,]$pid, ]$mode

## attr_o and pf_o filtering
cols = c("pf_o_att", "pf_o_sin", "pf_o_int", "pf_o_fun", "pf_o_amb", "pf_o_sha", "dec_o", "attr_o", "sinc_o", "intel_o", "fun_o", "amb_o", "shar_o", "like_o",  "prob_o")
for (col in cols) {
    pf_o <- SD %>%group_by(pid) %>%  summarize_at( .vars = col, .funs = mean)
    idx = which(is.na(SD[, col]) == T)
    pf_o[is.na(pf_o)] = 0
    SD[idx, col] = pf_o[SD[idx,]$pid, 2]
}

# adding one column with explanation for race column (matching index with race names)
race_idx <- unique(SD$race)
race_val <- c('Asian', 'European', 'Other', 'Latino', 'Black', NA)
SD$race_explained <- race_val[match(SD$race, race_idx)]
SD$race_explained_o <- race_val[match(SD$race_o, race_idx)]

# adding one column with explanation for field_cd column (matching index with race names)
# DISCUSS WITH ALVILS IMPUTING DATA INTO field_cd as 9 (because field is Operations Research)
field_idx <- c(1:18, NA)
field_val <- c('Law', 'Math', 'Social Science, Psychologist', 'Medical Science/Pharmaceuticals/Bio Tech',
               'Engineering', 'English/Creative Writing/ Journalism', 'History/Religion/Philosophy',
              'Business/Econ/Finance', 'Education, Academia', 'Biological Sciences/Chemistry/Physics', 
              'Social Work', 'Undergrad/undecided', 'Political Science/International Affairs',
              'Film', 'Fine Arts/Arts Administration', 'Languages', 'Architecture', 'Other', 'Other')
SD$field_explained <- field_val[match(SD$field_cd, field_idx)]

# converting income from string to numeric
SD$income <- as.numeric(gsub(',', "", SD$income, fixed = T))
sum(is.na(SD$income))
unique(SD$field_cd)
summary(SD[SD$wave >= 6 & SD$wave <= 9,129:134])

## removes any rows where the nb of NA values are greater than 0.25 (25%)
SD[SD==""]<-NA
SD = SD[, colSums(is.na(SD)) / dim(SD)[1] < 0.2]

# adds additional columns based on pid
cols = c("imprelig", "imprace", "goal", "date", "go_out",  "sports", "tvsports", "exercise", "dining", "museums", "art", "hiking","gaming", "clubbing", "reading", "tv", "theater", "movies", "concerts", "music", "shopping", "yoga", "exphappy") 
for (col in cols) {
    SD[,  paste(col, "_o", sep="")] = 0 
}
for(row in 1:nrow(SD)) {
  pid = SD[row, "pid"]
  tmp = SD[which(SD$iid == pid)[1], ]
  for (col in cols) {
      SD[row, paste(col, "_o", sep="")] = tmp[col] 
  }
}
  
# to remove
#cols = c("iid", "id", "idg", "condtn", "wave", "round", "position",  "order", "partner", "pid", "field", "field_cd",  "race", "from", "zipcode", "career", "career_c", "dec", "match_es", "satis_2", "length", "numdat_2", 'race', 'race_o', 'field_cd', 'field', 'int_corr', "dec_o", "race_explained","race_explained_o", "field_explained", "met", "met_o")

#SD = SD[ , -which(names(SD) %in% cols)]
#SD = SD[complete.cases(SD), ]

```

```{r}
# Importance of each attribute by gender
attr <- subset(SD, !duplicated(SD$iid), select = c(3, 70:75)) %>%
  filter(!is.na(attr1_1))  %>% # 7 people with missing values
  group_by(gender) %>%
  summarize(Attractiveness = mean(attr1_1),
            Sincerity = mean(sinc1_1),
            Intelligence = mean(intel1_1),
            Fun = mean(fun1_1, na.rm = T),
            Ambition = mean(amb1_1, na.rm = T),
            'Shared interests' = mean(shar1_1, na.rm = T))

data_long <- pivot_longer(attr, !gender) # manipulating data to  plot

data_long %>% ggplot(aes(x = name, y = value, fill = factor(gender))) + 
  geom_bar(stat = 'identity', position = 'dodge') +
  xlab('Attribute') + ylab('Importance') + ggtitle('Importance of each attribute by gender') +
  geom_text(aes(label = round(value, 2)), position=position_dodge(width=0.9), vjust = -0.5, size = 3.2) +
  scale_fill_discrete(name="Gender",
                         breaks=c(0, 1),
                         labels=c("Women", "Men")) + # Editing legend
  theme_minimal() + # Changing theme
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size = 12),
        axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size = 12)) # Centers title
```

```{r}
# Age analysis
sum(is.na(SD$age))
SD[is.na(SD$age), 1:10]

age_df <- subset(SD, !duplicated(SD[,1])) %>%
  filter(!is.na(age)) %>%
  group_by(wave, gender) %>%
  summarize(Average_age = mean(age))

SD %>% nrow()
nrow(SD)

age_df$gender <- ifelse(age_df$gender == 0, 'Women', 'Men')

# Mean age per wave
age_df %>% ggplot(aes(x = wave, y = Average_age, fill = gender)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  scale_fill_discrete(name = "Gender") 

age_df <- subset(SD, !duplicated(SD$iid), select = c(iid, gender, age)) %>%
  filter(!is.na(age)) %>%
  mutate(mean = mean(age))
age_df$gender <- ifelse(age_df$gender == 0, 'Women', 'Men')

# Histogram of age
max(unique(age_df$age)) - min(unique(age_df$age)) # number of bins
age_df %>% ggplot(aes(x = age)) + 
  geom_histogram(bins = 37, fill = 'lightgrey', position = 'identity', alpha = .7) +
  geom_vline(aes(xintercept = mean), col = 'red', linetype = 'dashed')
```

```{r}
# Field analysis
field_df <- subset(SD, !duplicated(SD$iid)) %>%
  filter(!is.na(field_cd)) %>%
  group_by(field_explained, gender) %>%
  summarize(field_sum = n())

field_df$gender <- ifelse(field_df$gender == 0, 'Women', 'Men')

field_df %>% ggplot(aes(x = field_explained, y = field_sum, fill = gender)) + 
  geom_bar(stat = 'identity', position = 'dodge') + 
  coord_flip()

```

```{r}
# Income
income_df <- subset(SD, !duplicated(SD$iid)) %>%
  filter(!is.na(income))

income_df$gender <- ifelse(income_df$gender == 0, 'Women', 'Men')

income_df %>% ggplot(aes(x = income/1000, fill = gender)) + 
  geom_histogram(bins = 15)

```

```{r}
# Purpose
goal_df <- subset(SD, !duplicated(SD$iid)) %>%
  filter(!is.na(goal)) %>%
  group_by(goal, gender) %>%
  summarise(count = n())

goal_df$gender <- ifelse(goal_df$gender == 0, 'Women', 'Men')

goal_idx <- unique(goal_df$goal)
goal_val <- c('Seemed like a fun night out', 'To meet new people', 'To get a date', 
              'Looking for a serious relationship', 'To say I did it',	'Other')
goal_df$goal_explained <- goal_val[match(goal_df$goal, goal_idx)]

goal_df %>% ggplot(aes(x = goal_explained, y = count, fill = gender)) + 
  geom_bar(stat = 'identity', position = 'dodge') +
  coord_flip()

```

```{r}
# Importance of features for men/women

```

## PCA

```{r}
colnames(SD)[51:67]

colnames(SD)[c(3, 15, 16, 51, 56:59, 63, 65, 66, 34,140:145, 130:136)]

Y <- subset(SD, !duplicated(SD$iid), select = c(51, 56:60, 63, 65, 66))
Y <- subset(SD, !duplicated(SD$iid), select = c(3, 15, 16, 51, 56:59, 63, 65, 66, 34,140:145, 130:136))
Y <- t(apply(Y, 1, '-', colMeans(Y, na.rm = T)))
s <- svd(Y[complete.cases(Y),])
diagS <- s$d
rho <- diagS^2/sum(diagS^2)
threshold = 0.9

xlimits <- c(1, ncol(Y)); 
plot(rho,
     type='o',
     main="Variance explained by principal components",
     xlab="Principal components", 
     ylab="Variance explained",
     xlim=xlimits,
     ylim=c(0,1),
     col='blue')
lines(cumsum(rho), type='o', col='orange')
lines(xlimits, c(threshold, threshold), lty='dashed')

legend("right", # Define position
       legend=c("Cumulative", "Individual", "Threshold"), # Set strings for legend
       col=c("orange", "blue", "black"), lty=c(1,1,2), # Match appereance of lines
       cex=1.5, bg='lightblue') # Setup how the box looks (cex controls size)
```

```{r}
## Scree plot

# chee plot
par(mfrow=c(1, 1))
eigenv = diagS^2
xlimits <- c(1, ncol(Y)); 
plot(eigenv,
     type='o',
     main="Scree plot",
     xlab="Principal component", 
     ylab="Eigenvalue",
     xlim=xlimits,
     col='blue')
```

## PCA 2 - 29.09
```{r}
cols <- c('gender', 'age', 'age_o', 'race_explained', 'race_explained_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr1_1', 'sinc1_1', 'intel1_1', 'amb1_1', 'shar1_1', 'attr', 'sinc', 'intel', 'amb', 'shar', 'attr_o', 'sinc_o', 'intel_o', 'amb_o', 'shar_o', 'like', 'like_o', 'prob', 'prob_o')
Y <- subset(SD, !duplicated(SD$iid), select = cols)

asian <- ifelse(Y$race_explained == 'Asian', 1, 0)
european <- ifelse(Y$race_explained == 'European', 1, 0)
other <- ifelse(Y$race_explained == 'Other', 1, 0)
latino <- ifelse(Y$race_explained == 'Latino', 1, 0)
black <- ifelse(Y$race_explained == 'Black', 1, 0)

asian_o <- ifelse(Y$race_explained_o == 'Asian', 1, 0)
european_o <- ifelse(Y$race_explained_o == 'European', 1, 0)
other_o <- ifelse(Y$race_explained_o == 'Other', 1, 0)
latino_o <- ifelse(Y$race_explained_o == 'Latino', 1, 0)
black_o <- ifelse(Y$race_explained_o == 'Black', 1, 0)

Y <- cbind(Y, asian, european, other, latino, black, asian_o, european_o, other_o, latino_o, black_o)

cols_cat <- c('asian', 'european', 'other', 'latino', 'black', 'asian_o', 'european_o', 'other_o', 'latino_o', 'black_o')

Y[, cols_cat] <- Y[, cols_cat]/sqrt(5)

colnames(Y)
Y <- Y[, -c(4, 5)] #deleting categorical variables race and race_o

Y_temp <- Y[, -which(colnames(Y) %in% c(cols_cat, 'gender'))]

Y_temp <- t(apply(Y_temp, 1, '-', colMeans(Y_temp, na.rm = T))) # subtracting mean

Y_temp <- t(apply(Y_temp, 1, '/', apply(Y_temp, 2, sd, na.rm = T))) # dividing by standard deviation
colnames(Y)
Y <- cbind(Y_temp, Y[, c(cols_cat, 'gender')])

Y <- t(apply(Y, 1, '-', colMeans(Y, na.rm = T)))

s <- svd(Y[complete.cases(Y),])
diagS <- s$d
rho <- diagS^2/sum(diagS^2)

threshold = 0.9


xlimits <- c(1, ncol(Y)); 
plot(rho,
     type='o',
     main="Variance explained by principal components",
     xlab="Principal components", 
     ylab="Variance explained",
     xlim=xlimits,
     ylim=c(0,1),
     col='blue')
lines(cumsum(rho), type='o', col='orange')
lines(xlimits, c(threshold, threshold), lty='dashed')
     

