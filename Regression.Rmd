---
title: "Regression"
author: "Katarzyna Otko"
date: "3 11 2020"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Linear regression model predicting positive rate

```{r}
library(tidyverse)
library(tidymodels)

setwd("C:/Users/katin/Desktop/Folder/STUDIA/DTU/Semestr I/Intro to ML/ML_speed_dating")

SD <- read.csv('SD_clean.csv')

# percentage of getting dec_o = 1 (if a participant had 10 dates and 5 partners chose dec = 1, then positive rate = 50%)
positive_rate <- SD %>% subset(select = c('iid', 'dec', 'dec_o')) %>%
  group_by(iid) %>%
  summarise(Rate = sum(dec_o)/n())

match_rate <- subset(SD, select = c('iid', 'match', 'dec', 'dec_o')) %>%
  group_by(iid) %>%
  summarise(match_rate = mean(match)) 

means_no_NA <- SD %>% subset(select = c('iid', 'attr_o', 'sinc_o', 'intel_o', 'amb_o', 'shar_o', 'fun_o', 'like_o')) %>%
  group_by(iid) %>%
  summarise(across(attr_o:like_o, mean)) %>%
  drop_na()

dataset <- left_join(means_no_NA, positive_rate, by = 'iid')


```


# According to scripts
Regression, part A - one-layer CV

```{r}
library(glmnet)
library(cvTools)
dataset <- left_join(means_no_NA, positive_rate, by = 'iid')
dataset <- dataset[, 2:9] # We dont want iid column
dataset <- cbind(const = rep(1,nrow(dataset)), dataset) # adding constant

K = 10
CV <- cvFolds(nrow(dataset), K=K)


M <- ncol(X)
lambda_tmp <- c(0, 10^seq(-3, 8, length.out = 20))
T <- length(lambda_tmp)

w <- matrix(nrow = M,ncol = K)
rownames(w) <- colnames(X)
coeff_per_lambda <- list()

Error_train <- matrix(nrow = T, ncol = K)
Error_test <- matrix(nrow = T, ncol = K)

for (i in 1:length(lambda_tmp)) {
  
    for (k in 1:K) {
    X_train <- X[CV$subsets[CV$which!=k], ];
    y_train <- y[CV$subsets[CV$which!=k]];
    X_test <- X[CV$subsets[CV$which==k], ];
    y_test <- y[CV$subsets[CV$which==k]];
    CV$TrainSize[k] <- length(y_train)
    CV$TestSize[k] <- length(y_test)
    
    mu <- colMeans(X_train[, 2:8])
    sigma <- apply(X_train[, 2:8], 2, sd)
    
    X_train[, 2:8] <- scale(X_train[, 2:8], mu, sigma)
    X_test[, 2:8] <- scale(X_test[, 2:8], mu, sigma)
      
    CV$TrainSize[k] <- length(y_train)
    CV$TestSize[k] <- length(y_test)
      
    Xty <- t(X_train) %*% y_train
    XtX <- t(X_train) %*% as.matrix(X_train)
    
    lambdaI = lambda_tmp[i]*diag(M);
    lambdaI[1, 1] = 0
    w[, k] <- solve(XtX+lambdaI) %*% Xty
    
    Error_train[i,k] = sum((y_train - as.matrix(X_train) %*% w[,k])^2)
    Error_test[i,k] = sum((y_test - as.matrix(X_test) %*% w[,k])^2)
    }
  coeff_per_lambda[[i]] <- w
}

train_error <- rowMeans(Error_train/CV$TrainSize)
test_error <- rowMeans(Error_test/CV$TestSize)

lambda_opt <- which.min(test_error)
lambda_tmp[lambda_opt]

# coefficients for optimal lambda

sort(rowMeans(coeff_per_lambda[[lambda_opt]]), decreasing = TRUE)
sort(rowMeans(coeff_per_lambda[[1]]), decreasing = TRUE)

```

## PLOTS

```{r}
par(mfrow=c(1,2))
par(mgp=c(2.5,1,0))

# Plot coefficients
w_mean <- matrix(nrow = M, ncol = T)
rownames(w_mean) <- rownames(w)
for (i in 1:length(coeff_per_lambda)) {
  lambda <- coeff_per_lambda[[i]]
  w_mean[,i] <- rowMeans(lambda)
}
w_mean <- w_mean[order(w_mean[,1], decreasing = T),]

colors_vector=rainbow(8)
plot(log(lambda_tmp), w_mean[2,], type = 'l', col = colors_vector[2], ylim = c(min(w_mean),0.13),
     ylab = 'Mean value of coefficients', xlab = 'Log(lambda)', main = 'Weights as a function of lambda')
points(log(lambda_tmp), w_mean[2,], col = colors_vector[2])

for (j in 3:M) {
  lines(log(lambda_tmp), w_mean[j,])
}

for(i in 3:M){
  points(log(lambda_tmp), w_mean[i,], col=colors_vector[i])
  lines(log(lambda_tmp), w_mean[i,], col=colors_vector[i])
}
abline(v = log(lambda_tmp[lambda_opt]), lty = 2)
legend_names <- names(w_mean[,1])[2:8]
legend("topright", legend = c(legend_names, 'Opt. lambda'), lty = c(rep(1, 7), 2), col = c(colors_vector[2:8], 'black'), cex = .9)

# Train/test error
plot(log(lambda_tmp), train_error, type = 'l',
      xlab="Log(lambda)", ylab="Error", main = 'Generalization error as a function of lambda',
     ylim = c(min(test_error), max(train_error)), col = 'red')
lines(log(lambda_tmp), test_error, col = 'blue')
legend('bottomright', legend = c('Test error', 'Training error', 'Opt. lambda'), col = c('blue', 'red', 'black'), lty= c(1, 1, 2), cex = .95)
abline(v = log(lambda_tmp[lambda_opt]), lty = 2)
text(13.2, 0.0255, paste0('Optimal lambda: ', round(lambda_tmp[lambda_opt], 2)))

coeff <- as.data.frame(sort(rowMeans(coeff_per_lambda[[lambda_opt]])[2:8], decreasing = TRUE))
#coeff$name <- names(coeff)
colnames(coeff) <- 'Coefficient'

coeff %>% ggplot(aes(Coefficient, reorder(rownames(coeff), Coefficient))) + geom_point(size = 4) +
  geom_vline(xintercept = 0, lty = 2) + 
  xlab('Value') + ylab('Coefficient') + ggtitle('Coefficients\' values for the optimal lambda')+
  theme_minimal() + # Changing theme
  theme(plot.title = element_text(hjust = 0.5), # Centers title
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size = 12), # x/y labels position
        axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size = 12)) 

```

# Regression, part B

```{r}

###############
# data init
#############
data = dataset[,2:ncol(dataset)]
x = data[, -ncol(data)]
y = data[, ncol(data)]
x = scale(x)
transformed_data = as.data.frame(cbind(x, rate=y))


#################
#L2 reg
################

l2_reg <- function(train_source, train_target, test_source, test_target, lambda) {

    # train model
    net <- glmnet(data.matrix(train_source), 
                        data.matrix(train_target), 
                        alpha = 0,                             
                        lambda = lambda)
    
    # train error
    train_res = predict(net, data.matrix(train_source) ,s=lambda)
    train_error = mean((train_res - train_target)^2)
    
    # test error
    test_res = predict(net, data.matrix(test_source) ,s=lambda)
    test_error = mean((test_res - test_target)^2)

    return (list(train_error, test_error))
}



outer_nb_folds = 10
inner_nb_folds = 10
params = seq(0, 1, by = 0.1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

set.seed(123)
# creates nested crossvalidation both inside and outside fold is stratified
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = l2_reg(inner_train[, -ncol(inner_train)],
                     inner_train[, ncol(inner_train)],
                     inner_test[, -ncol(inner_test)],
                     inner_test[, ncol(inner_test)],
                     params[k])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  error = l2_reg(outer_train[, -ncol(outer_train)],
                 outer_train[, ncol(outer_train)],
                 outer_test[, -ncol(outer_test)],
                 outer_test[, ncol(outer_test)],
                 params[min_idx])
  error_per_fold[i] = error[[2]]

}

# for table for project 2
l2_gen_error = mean(error_per_fold); l2_gen_error
l2_error_per_fold = error_per_fold; l2_error_per_fold
l2_params = params; l2_params
l2_best_hyperparam_per_fold = best_model_hyperparam; l2_best_hyperparam_per_fold
```

# Baseline

```{r}
#################
#Base model
################

base <- function(train_source, train_target, test_source, test_target) {
    # train error
    train_res = mean(train_target)
    train_error = mean((train_res - train_target)^2)
    # test error
    test_res = train_res
    test_error = mean((test_res - test_target)^2)
    return (list(train_error, test_error))
}



outer_nb_folds = 10
inner_nb_folds = 10
params = c(1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

set.seed(123)
# creates nested crossvalidation both inside and outside fold is stratified
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = base(inner_train[, -ncol(inner_train)],
                     inner_train[, ncol(inner_train)],
                     inner_test[, -ncol(inner_test)],
                     inner_test[, ncol(inner_test)])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  error = base(outer_train[, -ncol(outer_train)],
                 outer_train[, ncol(outer_train)],
                 outer_test[, -ncol(outer_test)],
                 outer_test[, ncol(outer_test)])
  error_per_fold[i] = error[[2]]

}

# for table for project 2
base_gen_error = mean(error_per_fold)
base_error_per_fold = error_per_fold
base_params = params
base_best_hyperparam_per_fold = best_model_hyperparam
```

# ANN

```{r}


#################
#ANN reg
################

ann <- function(train, test, nb_hidden_units) {
    train_source = train[, -ncol(train)]
    train_target = train[, ncol(train)]
    test_source = test[, -ncol(test)]
    test_target = test[, ncol(test)]
    
    source_formula <- paste(c(colnames(train[,1:ncol(train)-1])),collapse="+")
    target_formula = paste(c(colnames(train)[ncol(train)], "~"),collapse="")
    f <- formula(paste(c(target_formula, source_formula),collapse=""))
    
    # train model
    net = neuralnet(f, train, hidden=nb_hidden_units, act.fct='tanh', linear.output=TRUE, err.fct='sse');

    # train error
    train_res = compute(net, train_source)
    train_error = mean((train_res$net.result - train_target)^2)
    
    # test error
    test_res = compute(net, test_source)
    test_error = mean((test_res$net.result - test_target)^2)

    return (list(train_error, test_error))
}



outer_nb_folds = 10
inner_nb_folds = 10
params = seq(7, 8, by = 1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

set.seed(123)
# creates nested crossvalidation
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = ann(inner_train,
                     inner_test,
                     params[k])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
      print("inner")
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  error = ann(outer_train,
                 outer_test,
                 params[min_idx])
  error_per_fold[i] = error[[2]]
  print(i)
  print("outer")


}

# for table for project 2
ann_gen_error = mean(error_per_fold); 
ann_error_per_fold = error_per_fold; 
ann_params = params;
ann_best_hyperparam_per_fold = best_model_hyperparam



#################
#Best hyperparam
################
nb_folds = 10
params = seq(1, 20, by = 1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = matrix(0L, nrow = nb_folds, ncol = nb_params)

for (i in 1:nb_folds) {
  # divides in outer train/test
  fold_data = folds$splits[[i]]$data
  idx_train = folds$splits[[i]]$in_id
  idx_test = -which(as.numeric(rownames(fold_data)) %in% idx_train)
  train = fold_data[idx_train, ]
  test = fold_data[idx_test, ]
  # hyperparam optim
  for (j in 1:nb_params) {
    # trains model and gets train and test error
    error = ann(train,
                test,
                params[j])
    # inner error for each inner fold
    error_per_fold[i, j] = error[[2]]
    print(i, j)

  }
}
gen_error = colMeans(error_per_fold)
min_idx = which.min(gen_error)
best_model_hyperparam = min_idx


```

# Statistical evaluation

```{r}
##############
# t test 
##############

outer_nb_folds = 30
inner_nb_folds = 10
params = seq(0, 1, by = 0.1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

set.seed(123)
# creates nested crossvalidation
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = l2_reg(inner_train[, -ncol(inner_train)],
                     inner_train[, ncol(inner_train)],
                     inner_test[, -ncol(inner_test)],
                     inner_test[, ncol(inner_test)],
                     params[k])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  error = l2_reg(outer_train[, -ncol(outer_train)],
                 outer_train[, ncol(outer_train)],
                 outer_test[, -ncol(outer_test)],
                 outer_test[, ncol(outer_test)],
                 params[min_idx])
  error_per_fold[i] = error[[2]]

}

# for table for project 2
l2_error_per_fold_ttest = error_per_fold; 





params = c(1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

set.seed(123)
# creates nested crossvalidation
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = base(inner_train[, -ncol(inner_train)],
                     inner_train[, ncol(inner_train)],
                     inner_test[, -ncol(inner_test)],
                     inner_test[, ncol(inner_test)])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  error = base(outer_train[, -ncol(outer_train)],
                 outer_train[, ncol(outer_train)],
                 outer_test[, -ncol(outer_test)],
                 outer_test[, ncol(outer_test)])
  error_per_fold[i] = error[[2]]

}

# for table for project 2
base_gen_error = mean(error_per_fold)
base_error_per_fold_ttest = error_per_fold




params = seq(7, 8, by = 1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

set.seed(123)
# creates nested crossvalidation
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = ann(inner_train,
                     inner_test,
                     params[k])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
      print("inner")
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  error = ann(outer_train,
                 outer_test,
                 params[min_idx])
  error_per_fold[i] = error[[2]]
  print(i)
  print("outer")


}

# for table for project 2
ann_gen_error = mean(error_per_fold); 
ann_error_per_fold_ttest = error_per_fold; 





# ann vs base
z = ann_error_per_fold_ttest - base_error_per_fold_ttest
ttest_ann_base = t.test(z, alternative = "two.sided", alpha=0.05)


# l2 vs base
z = l2_error_per_fold_ttest - base_error_per_fold_ttest
ttest_l2_base = t.test(z, alternative = "two.sided", alpha=0.05)


# ann vs l2
z = ann_error_per_fold_ttest - l2_error_per_fold_ttest
ttest_l2_base = t.test(z, alternative = "two.sided", alpha=0.05)


```