---
title: "SD_project2"
author: "Katarzyna Otko"
date: "3 11 2020"
output: html_document
---

```{r}
library(data.table)    # provides enhanced data.frame
library(ggplot2)       # plotting
library(glmnet)        # ridge, elastic net, and lasso 
library(FNN)           # KNN
library(R.utils)
library(tidymodels)


# helper functions
SampleWeight <- function(target, weights) {
  weight_per_sample = target
  weight_per_sample[weight_per_sample == 0] = weights[1]
  weight_per_sample[weight_per_sample == 1] = weights[2]
  return (weight_per_sample)
}


l2_reg <- function(train_source, train_target, test_source, test_target, lambda, weights, tresh) {

    # train model
    net <- glmnet(data.matrix(train_source), 
                        data.matrix(train_target), 
                        alpha = 0,                             
                        lambda = lambda, 
                        weights = weights,
                        family="binomial")
    
    # train error
    train_res = predict(net, data.matrix(train_source) ,s=lambda)
    train_res[train_res < tresh] = 0
    train_res[train_res >= tresh] = 1
    train_error = 1 - (sum(train_res == train_target) / length(train_target))
    
    # test error
    test_res = predict(net, data.matrix(test_source) ,s=lambda)
    test_res[test_res < tresh] = 0
    test_res[test_res >= tresh] = 1
    test_error = 1 - (sum(test_res == test_target) / length(test_target))
    return (list(train_error, test_error, test_res))
}


######################################################
# data loading
#####################################################
# Alvils
data <- read.csv('/home/nomow/Documents/DTU/Intro_to_machine_learning/ML_speed_dating/SD_clean.csv')
# Kasia
setwd("C:/Users/katin/Desktop/Folder/STUDIA/DTU/Semestr I/Intro to ML/ML_speed_dating")
data <- read.csv('SD_clean.csv')

# removes columns that are irrevelant
rm_cols = c("X","iid", "id", "idg", "condtn", "wave", "round", "position",  "order", "partner", "pid", "field", "field_cd",  "race", "from", "zipcode", "career", "career_c", "dec", "match_es", "satis_2", "length", "numdat_2", 'race', 'race_o', 'field_cd', 'field', 'int_corr', "dec_o", "race_explained","race_explained_o", "field_explained", "met", "met_o", "like", "like_o")
data = data[ , -which(names(data) %in% rm_cols)]


######################################################
## Feature selection
######################################################
feature_names = c("age", "age_o", "go_out", "sports", "tvsports", "exercise", "dining", "museums", "art", "hiking","gaming", "clubbing", "reading", "tv", "theater", "movies", "concerts", "music", "shopping", "yoga", 
 "exphappy", "go_out_o", "sports_o", "tvsports_o", "exercise_o", "dining_o", "museums_o", "art_o", "hiking_o", "gaming_o", "clubbing_o",
 "reading_o", "tv_o", "theater_o", "mvies_o", "concerts_o", "music_o", "shopping_o", "yoga_o", "exphappy_o")
# data normalization
x = (data[, -2])
x = scale(x)
y = (data[, 2])

# l1 logistic regression model, where we choose features which weights are not 0
l1_net <- cv.glmnet(data.matrix(x), data.matrix(y), family="binomial", alpha=1)
best_lambda_lasso <- l1_net$lambda.1se  # largest lambda in 1 SE
lasso_coef <- l1_net$glmnet.fit$beta[,  # retrieve coefficients
              l1_net$glmnet.fit$lambda  # at lambda.1se
              == best_lambda_lasso]

# adds features to use from manual selection and automatic
features_to_use = unique(c(feature_names, colnames(x)[which(lasso_coef != 0)]))
x = x[ , which(colnames(x) %in% features_to_use)]


colnames(l1_net$glmnet.fit$beta)
l1_net$lambda
sort(round(lasso_coef, 2))


```


# Regularized logistic regression

```{r}
##########################
## L2 logistic regression
##########################

## sample weighting
weights_per_class = 1 / (table(y) / length(y))

# nested cross-validation
transformed_data = as.data.frame(cbind(x, match=y))
outer_nb_folds = 10
inner_nb_folds = 10
tresh = 0.5
params = seq(0, 1, by = 0.1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

y_hat_lr <- rep(NA, nrow(transformed_data))

#################
# nested crossval
#################

set.seed(123)
# creates nested crossvalidation both inside and outside fold is stratified
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(strata = match,  v = outer_nb_folds), 
                     inside = vfold_cv(strata = match,  v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    
    # hyperparam optim
    for (k in 1:nb_params) {
      weights_inner = SampleWeight(inner_train[, ncol(inner_train)], weights_per_class)
      # trains model and gets train and test error
      error = l2_reg(inner_train[, -ncol(inner_train)],
                     inner_train[, ncol(inner_train)],
                     inner_test[, -ncol(inner_test)],
                     inner_test[, ncol(inner_test)],
                     params[k],
                     weights_inner, 
                     tresh)
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  weights_outer = SampleWeight(outer_train[, ncol(outer_train)], weights_per_class)
  error = l2_reg(outer_train[, -ncol(outer_train)],
                 outer_train[, ncol(outer_train)],
                 outer_test[, -ncol(outer_test)],
                 outer_test[, ncol(outer_test)],
                 params[min_idx],
                 weights_outer, 
                 tresh)
  error_per_fold[i] = error[[2]]
  # obtains predictions for McNemar test
  y_hat_lr[idx_outer_test] <- error[[3]]

}

# for table for project 2
l2_gen_error = mean(error_per_fold); l2_gen_error
l2_error_per_fold = error_per_fold; l2_error_per_fold
l2_params = params; l2_params
l2_best_hyperparam_per_fold = best_model_hyperparam; l2_best_hyperparam_per_fold

######################################
## final param selection using crossval
######################################
weights = SampleWeight(y, weights_per_class)
l2_net <- cv.glmnet(data.matrix(x), data.matrix(y), family="binomial", alpha=0, lambda = params, weights = weights)
best_lambda_l2 <- l2_net$lambda.1se  # largest lambda in 1 SE
best_lambda_l2

ridge_coef <- l2_net$glmnet.fit$beta[,  # retrieve coefficients
              l2_net$glmnet.fit$lambda  # at lambda.1se
              == best_lambda_l2]

ridge_coef <- sort(ridge_coef, decreasing = T) %>% as.data.frame()
colnames(ridge_coef) <- 'Coefficient'

ridge_coef[order(Coefficient),]

ridge_coef  %>%
  ggplot(aes(y = reorder(rownames(ridge_coef), Coefficient), x = Coefficient)) + 
  geom_point() + 
  geom_vline(xintercept = 0, lty = 2) +
  ylab("Feature") + ggtitle("Logistic regression coefficients") +
  theme_minimal() + # Changing theme
  theme(plot.title = element_text(hjust = 0.5), # Centers title
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size = 12), # x/y labels position
        axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size = 12))

coeffs <- sort(rowMeans(l2_net$glmnet.fit$beta), decreasing = TRUE)
coeffs_to_plot <- coeffs[c(1:8, 57)] %>% as.data.frame()
coeffs_to_plot 

coeffs_to_plot %>% ggplot(aes(y = rownames(coeffs_to_plot), x = .)) + geom_point()


length(coeffs)



```


# KNN

```{r}

# nested cross-validation
transformed_data = as.data.frame(cbind(x, match=y))
k_params <- c(1, 3, 5, 7)
nb_params <- length(k_params)
outer_nb_folds <- 10
inner_nb_folds <- 10
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

y_hat_knn <- rep(NA, nrow(transformed_data))

#################
# nested crossval
#################
set.seed(123)
# creates nested crossvalidation both inside and outside fold is stratified
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(strata = match,  v = outer_nb_folds), 
                     inside = vfold_cv(strata = match,  v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    
    # hyperparam optim
    for (k in 1:nb_params) {
      x_inner_train <- inner_train[, 1:(ncol(inner_train) - 1)]
      y_inner_train <- inner_train[, 'match']
      x_inner_test <- inner_test[, 1:(ncol(inner_train) - 1)]
      y_inner_test <- inner_test[, 'match']
      
      # trains model and gets a test error
      y_pred <- knn(x_inner_train, 
                    x_inner_test, 
                    y_inner_train,
                    k = k_params[k],
                    algorithm = "kd_tree")
      
      # inner error for each inner fold
      inner_error[j, k] <- 1 - (sum(y_pred == y_inner_test) / length(y_inner_test))
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  
  x_outer_train <- outer_train[, 1:(ncol(outer_train) - 1)]
  y_outer_train <- outer_train[, 'match']
  x_outer_test <- outer_test[, 1:(ncol(outer_train) - 1)]
  y_outer_test <- outer_test[, 'match']
      
  # trains model and gets a test error
  y_pred <- knn(x_outer_train, 
                x_outer_test, 
                y_outer_train,
                k = k_params[min_idx],
                algorithm = "kd_tree")
  error_per_fold[i] <- 1 - (sum(y_pred == y_outer_test) / length(y_outer_test))
  
  # obtains predictions for McNemar test
  y_hat_knn[idx_outer_test] <- as.numeric(as.character(y_pred))

}

table(y_pred, y_outer_test)

knn_gen_error = mean(error_per_fold); knn_gen_error
knn_error_per_fold = error_per_fold; knn_error_per_fold
knn_params = k_params; knn_params
knn_best_hyperparam_per_fold = k_params[best_model_hyperparam]; knn_best_hyperparam_per_fold

######################################
## final param selection using crossval
######################################
weights = SampleWeight(y, weights_per_class)
l2_net <- cv.glmnet(data.matrix(x), data.matrix(y), family="binomial", alpha=0, lambda = params, weights = weights)
best_lambda_l2 <- l2_net$lambda.1se 


dim(inner_train)

```


# Baseline

```{r}

base <- function(train_source, train_target, test_source, test_target) {
    train_counts <- as.data.frame(table(train_target))
    most_frequent_class <- train_counts[which.max(train_counts$Freq), 'train_target'] %>% as.character() %>% as.numeric()
    # train error
    train_error = 1 - (sum(train_target == most_frequent_class) / length(train_target))
    # test error
    test_error = 1 - (sum(test_target == most_frequent_class) / length(test_target))
    return (list(train_error, test_error, most_frequent_class))
}


outer_nb_folds = 10
inner_nb_folds = 10
params = c(1)
nb_params = length(params)
best_model_hyperparam = rep(0, (nb_params - 1))
error_per_fold = rep(0, outer_nb_folds)

y_hat_base <- rep(NA, nrow(transformed_data))

set.seed(123)
# creates nested crossvalidation both inside and outside fold is stratified
folds <- nested_cv(transformed_data, 
                     outside = vfold_cv(v = outer_nb_folds), 
                     inside = vfold_cv(v = inner_nb_folds))


# outer fold 
for (i in 1:outer_nb_folds) {
  # divides in outer train/test
  outer_data = folds$splits[[i]]$data
  idx_outer_train = folds$splits[[i]]$in_id
  idx_outer_test = -which(as.numeric(rownames(outer_data)) %in% idx_outer_train)
  outer_train = outer_data[idx_outer_train, ]
  outer_test = outer_data[idx_outer_test, ]
  inner_error = matrix(0L, nrow = inner_nb_folds, ncol = nb_params)
  
  # inner fold
  for (j in 1:inner_nb_folds) {
    # divides in inner train/test
    inner_data = folds$inner_resamples[[i]]$splits[[j]]$data
    idx_inner_train = folds$inner_resamples[[i]]$splits[[j]]$in_id
    idx_inner_test = -which(as.numeric(rownames(inner_data)) %in% idx_inner_train)
    inner_train = inner_data[idx_inner_train, ]
    inner_test = inner_data[idx_inner_test, ]
    # hyperparam optim
    for (k in 1:nb_params) {
      # trains model and gets train and test error
      error = base(inner_train[, -ncol(inner_train)],
                     inner_train[, ncol(inner_train)],
                     inner_test[, -ncol(inner_test)],
                     inner_test[, ncol(inner_test)])
      # inner error for each inner fold
      inner_error[j, k] = error[[2]]
    }
  }
  
  # calculates avg error for each model in inner fold and trains once more where the generalization error is minimum
  min_idx = which.min(colMeans(inner_error))
  best_model_hyperparam[i] = min_idx
  #class0_to_1 <- 
  
  error = base(outer_train[, -ncol(outer_train)],
                 outer_train[, ncol(outer_train)],
                 outer_test[, -ncol(outer_test)],
                 outer_test[, ncol(outer_test)])
  error_per_fold[i] = error[[2]]

  # obtains predictions for McNemar test
  y_hat_base[idx_outer_test] <- rep(error[[3]], length(outer_test[, ncol(outer_test)]))

}

# for table for project 2
base_gen_error = mean(error_per_fold); base_gen_error
base_error_per_fold = error_per_fold; base_error_per_fold
base_params = params; base_params
base_best_hyperparam_per_fold = best_model_hyperparam; base_best_hyperparam_per_fold

```


# Statistical evaluation

```{r}
source("C:/Users/katin/Desktop/Folder/STUDIA/DTU/Semestr I/Intro to ML/02450Toolbox_R/setup.R")

models <- list(y_hat_lr, y_hat_knn, y_hat_base)
alpha <- c(0.01, 0.05, 0.1)
pvalues <- rep(NA, 3)
names(pvalues) <- c('lr_knn', 'lr_base', 'knn_base')
CIs <- list()
for (a in 1:3) {
  CIs[[a]] <- matrix(NA, 3, 2); rownames(CIs[[a]]) = c('lr_knn', 'lr_base', 'knn_base')
  rt_lr_knn <- mcnemar(transformed_data[,'match'], models[[1]], models[[2]], alpha=alpha[a])
  pvalues[1] <- rt_lr_knn$p
  CIs[[a]][1,] <- rt_lr_knn$CI
  
  rt_lr_base <- mcnemar(transformed_data[,'match'], models[[1]], models[[3]], alpha=alpha[a])
  pvalues[2] <- rt_lr_base$p
  CIs[[a]][2,] <- rt_lr_base$CI
  
  rt_knn_base <- mcnemar(transformed_data[,'match'], models[[2]], models[[3]], alpha=alpha[a])
  pvalues[3] <- rt_knn_base$p
  CIs[[a]][3,] <- rt_knn_base$CI

}
names(CIs) <- c('alpha = 0.01', 'alpha = 0.05', 'alpha = 0.1')
CIs
round(pvalues, 3)

```