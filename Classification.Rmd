---
title: "SD_project2"
author: "Katarzyna Otko"
date: "3 11 2020"
output: html_document
---

# Classification

## Data preparation

```{r}
#install.packages("sjmisc")
library(sjmisc)

cols <- c('iid', 'gender', 'age', 'age_o', 'race_explained', 'race_explained_o', 'samerace', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr1_1', 'sinc1_1', 'intel1_1', 'amb1_1', 'shar1_1', 'attr', 'sinc', 'intel', 'amb', 'shar', 'attr_o', 'sinc_o', 'intel_o', 'amb_o', 'shar_o', 'like', 'like_o', 'prob', 'prob_o', 'match')

df <- subset(SD, select = c('iid', 'attr', 'attr3_1', 'match')) %>%
  mutate(diff = attr3_1 - attr) %>%
  group_by(iid) %>%
  summarise(mean_diff = mean(diff, na.rm = T),
            type = case_when(mean_diff < -1.5 ~ 'underestimated',
                             mean_diff > 1.5 ~ 'overestimated',
                             TRUE ~ 'realistic')) %>%
  add_column(positive_rate = positive_rate$Rate, match_rate = match_rate$match_rate)
df

age_mean <- as.integer(mean(SD$age, na.rm = T))

data <- SD[, cols]
data <- left_join(data, df, by = 'iid') %>%
  tidyr::replace_na(list(age = age_mean, age_o = age_mean)) %>%
  mutate(age_gap = abs(age - age_o)) %>%
  subset(select = c(-age, -age_o, -iid, -type, -race_explained, -race_explained_o, -positive_rate, -match_rate)) %>%
  drop_na() %>% 
  mutate(gender = as.factor(gender),
         samerace = as.factor(samerace),
         match = as.factor(match))
  
sum(is.na(data)); dim(SD); dim(data); colnames(data)

levels(data$match) # Need to change the levels because the models view the first level as positive
data <- data %>%
  mutate(match = fct_rev(match))

```

## Building a model (KNN)

```{r}
set.seed(456)
data_split <- initial_split(data, strata = match)
train <- training(data_split)
test <- testing(data_split)

set.seed(456)
folds <- vfold_cv(train, strata = match)
folds

# Defining a recipe
data_rec <- recipe(match ~ ., data = train) %>%
  step_normalize(all_numeric())

# Executing the recipe
norm <- data_rec %>% prep() %>% juice()
norm %>% select(where(is.numeric)) %>% sapply(mean)
norm %>% select(where(is.numeric)) %>% sapply(sd)

# Selecting metrics
c_metrics <- metric_set(accuracy, sens, roc_auc, mn_log_loss)

# Saving predictions
model_control <- control_grid(save_pred = T)

# Defining a model
#install.packages('kknn')
library(kknn)
knn_spec <- nearest_neighbor(neighbors = tune()) %>%
  set_mode('classification') %>%
  set_engine('kknn')

knn_grid <- grid_regular(parameters(knn_spec), levels = 5)

knn_tune <- tune_grid(
  knn_spec,
  data_rec,
  resamples = folds,
  control = model_control,
  metrics = c_metrics
)

# Plotting metrics
collect_metrics(knn_tune) %>%
  ggplot(aes(x = neighbors, y = mean)) + 
  geom_point() + geom_line() + 
  facet_wrap(~.metric, scales = 'free_y')

# to see variance between each fold
knn_tune %>% select(id, .metrics) %>%
  unnest(.metrics) %>%
  ggplot(aes(x = neighbors, y = .estimate, color = id)) + geom_point() + geom_line() + 
  facet_wrap(~.metric, scales = 'free_y')

data_metrics <- knn_tune %>% collect_predictions() %>%
  mutate(pred = if_else(.pred_1 >= .5, 1, 0),
         pred = as.factor(pred),
         pred = fct_rev(pred)) 

data_metrics %>%
  group_by(id) %>%
  summarise()

data_metrics %>%
  conf_mat(match, pred) #quite a lot of false negatives :/

data_metrics %>% accuracy(match, pred)
data_metrics %>% sens(match, pred) # pooor sensitivity
data_metrics %>% ppv(match, pred) 

# roc curve
knn_tune %>% collect_predictions() %>%
  group_by(id) %>%
  roc_curve(match, .pred_1) %>%
  autoplot()

# gain curve - how much of the class I encapture given the class probabilities, that is, if we say that everyone with the 50% prob. or less being a "match" (1) class, we can capture around 80% of the actual points
knn_tune %>% 
  collect_predictions() %>%
  gain_curve(match, .pred_1) %>%
  autoplot()
  
# Collect metrics and fit to a model
knn_tune %>% select_best(metric = 'roc_auc')
knn_tune %>% select_best(metric = 'accuracy')

# Defining a final model
knn_spec_final <- nearest_neighbor(neighbors = 14) %>%
  set_mode('classification') %>%
  set_engine('kknn')

# Defining a workflow
final_model <- workflow() %>%
  add_model(knn_spec_final) %>%
  add_recipe(data_rec)

# Fitting a final model
final_results <- last_fit(final_model, data_split)

# if we say 50% of these people got match, around 50% of those people actually got match
final_results %>% collect_predictions() %>%
  select(.pred_1, match) %>%
  mutate(.pred = 100*.pred_1) %>%
  select(-.pred_1) %>%
  mutate(.pred = round(.pred/5)*5) %>% #rounding to 5
  count(.pred, match) %>%
  pivot_wider(names_from = match, values_from = n) %>%
  rename(Yes = `1`, No = `0`) %>%
  mutate(prob = Yes/(Yes + No)) %>%
  mutate(prob = prob*100) %>%
  ggplot(aes(x = .pred, y = prob)) + geom_point() + geom_smooth() + geom_abline() +
  coord_fixed(ylim = c(0,100), xlim = c(0, 100))

```















